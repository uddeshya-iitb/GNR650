{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "torch.cuda.is_available()\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:krdylcze) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇██</td></tr><tr><td>train_loss</td><td>▆█▃▃▂▃▂▂▃▂▂▄▁▁▂▂▁▂▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>train_loss</td><td>1.59777</td></tr><tr><td>trainer/global_step</td><td>999</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">curious-sun-3</strong> at: <a href='https://wandb.ai/22m215/resnet18_cifar10_subsampled_demo1/runs/krdylcze' target=\"_blank\">https://wandb.ai/22m215/resnet18_cifar10_subsampled_demo1/runs/krdylcze</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230807_130406-krdylcze/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:krdylcze). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f17dcd324442a2a09a8bb1bdd189fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016672793883238533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/cminds/CMInDS/Uddeshya/GNR 650/wandb/run-20230807_132431-5flmugw8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/22m215/resnet18_cifar10_subsampled_demo1/runs/5flmugw8' target=\"_blank\">vibrant-snowball-5</a></strong> to <a href='https://wandb.ai/22m215/resnet18_cifar10_subsampled_demo1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/22m215/resnet18_cifar10_subsampled_demo1' target=\"_blank\">https://wandb.ai/22m215/resnet18_cifar10_subsampled_demo1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/22m215/resnet18_cifar10_subsampled_demo1/runs/5flmugw8' target=\"_blank\">https://wandb.ai/22m215/resnet18_cifar10_subsampled_demo1/runs/5flmugw8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | resnet18  | ResNet           | 11.2 M\n",
      "1 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.727    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4563baa22143eca538a7d2a172afcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pytorch_lightning as pl\n",
    "import torchvision.models as models\n",
    "import wandb\n",
    "from wandb import init\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import torch.nn as nn\n",
    "\n",
    "# Seed is not working\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "pl.seed_everything(42)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Your code to define LightningModule and Trainer goes here...\n",
    "\n",
    "# Step 1: Load and Subsample the CIFAR10 Data\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "indices = []\n",
    "for i in range(10):  # 10 classes in CIFAR10\n",
    "    class_indices = [idx for idx, label in enumerate(train_dataset.targets) if label == i]\n",
    "    indices.extend(class_indices[:100])\n",
    "\n",
    "subsampled_train_dataset = torch.utils.data.Subset(train_dataset, indices)\n",
    "train_loader = torch.utils.data.DataLoader(subsampled_train_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Step 2: Define the Lightning Module\n",
    "\n",
    "class ResNet18Lightning(pl.LightningModule):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet18Lightning, self).__init__()\n",
    "        self.resnet18 = models.resnet18(pretrained=False, num_classes=num_classes)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet18(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "        return optimizer\n",
    "\n",
    "# Step 3: Train with wandb logging\n",
    "\n",
    "wandb.init(project='resnet18_cifar10_subsampled_demo1')\n",
    "wandb_logger = WandbLogger()\n",
    "\n",
    "model = ResNet18Lightning().cuda()\n",
    "trainer = pl.Trainer(max_epochs=20, accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\", logger=wandb_logger)\n",
    "\n",
    "# trainer = pl.Trainer(max_epochs=5, gpus=1 if torch.cuda.is_available() else 0, logger=wandb_logger)\n",
    "trainer.fit(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming model is an instance of ResNet18Lightning\n",
    "\n",
    "# 1. Check the Magnitudes of the Weights:\n",
    "\n",
    "print(\"Weight Magnitudes (L2 Norm) for each layer:\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name}: {torch.norm(param.data):.4f}\")\n",
    "\n",
    "# 2. Visualize Kernels:\n",
    "\n",
    "def visualize_kernels(layer_weights, num_kernels=6):\n",
    "    # Assuming layer_weights is of shape (out_channels, in_channels, kernel_height, kernel_width)\n",
    "    for i in range(min(num_kernels, layer_weights.shape[0])):\n",
    "        plt.subplot(1, num_kernels, i + 1)\n",
    "        # Take the mean over all input channels to get a single 2D image for visualization\n",
    "        plt.imshow(layer_weights[i].mean(0).cpu().detach().numpy(), cmap='viridis')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the kernels of the first convolutional layer\n",
    "print(\"\\nVisualizing kernels of the first convolutional layer:\")\n",
    "first_layer_weights = model.resnet18.conv1.weight.data\n",
    "visualize_kernels(first_layer_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet18.conv1.weight: 9.8421\n",
      "resnet18.bn1.weight: 8.0017\n",
      "resnet18.bn1.bias: 0.6670\n",
      "resnet18.layer1.0.conv1.weight: 11.8414\n",
      "resnet18.layer1.0.bn1.weight: 7.6199\n",
      "resnet18.layer1.0.bn1.bias: 0.4097\n",
      "resnet18.layer1.0.conv2.weight: 11.7206\n",
      "resnet18.layer1.0.bn2.weight: 7.4228\n",
      "resnet18.layer1.0.bn2.bias: 0.2968\n",
      "resnet18.layer1.1.conv1.weight: 11.4897\n",
      "resnet18.layer1.1.bn1.weight: 7.6158\n",
      "resnet18.layer1.1.bn1.bias: 0.2748\n",
      "resnet18.layer1.1.conv2.weight: 11.3751\n",
      "resnet18.layer1.1.bn2.weight: 7.4234\n",
      "resnet18.layer1.1.bn2.bias: 0.2078\n",
      "resnet18.layer2.0.conv1.weight: 11.8333\n",
      "resnet18.layer2.0.bn1.weight: 10.7678\n",
      "resnet18.layer2.0.bn1.bias: 0.2659\n",
      "resnet18.layer2.0.conv2.weight: 16.0075\n",
      "resnet18.layer2.0.bn2.weight: 10.6751\n",
      "resnet18.layer2.0.bn2.bias: 0.2699\n",
      "resnet18.layer2.0.downsample.0.weight: 10.9528\n",
      "resnet18.layer2.0.downsample.1.weight: 10.9444\n",
      "resnet18.layer2.0.downsample.1.bias: 0.2699\n",
      "resnet18.layer2.1.conv1.weight: 15.9238\n",
      "resnet18.layer2.1.bn1.weight: 10.7672\n",
      "resnet18.layer2.1.bn1.bias: 0.2297\n",
      "resnet18.layer2.1.conv2.weight: 15.7908\n",
      "resnet18.layer2.1.bn2.weight: 10.6850\n",
      "resnet18.layer2.1.bn2.bias: 0.1724\n",
      "resnet18.layer3.0.conv1.weight: 16.2253\n",
      "resnet18.layer3.0.bn1.weight: 15.2269\n",
      "resnet18.layer3.0.bn1.bias: 0.2152\n",
      "resnet18.layer3.0.conv2.weight: 22.1628\n",
      "resnet18.layer3.0.bn2.weight: 15.2321\n",
      "resnet18.layer3.0.bn2.bias: 0.1913\n",
      "resnet18.layer3.0.downsample.0.weight: 15.4160\n",
      "resnet18.layer3.0.downsample.1.weight: 15.2531\n",
      "resnet18.layer3.0.downsample.1.bias: 0.1913\n",
      "resnet18.layer3.1.conv1.weight: 22.0006\n",
      "resnet18.layer3.1.bn1.weight: 15.2266\n",
      "resnet18.layer3.1.bn1.bias: 0.1429\n",
      "resnet18.layer3.1.conv2.weight: 21.9160\n",
      "resnet18.layer3.1.bn2.weight: 15.1973\n",
      "resnet18.layer3.1.bn2.bias: 0.1186\n",
      "resnet18.layer4.0.conv1.weight: 22.1899\n",
      "resnet18.layer4.0.bn1.weight: 21.5333\n",
      "resnet18.layer4.0.bn1.bias: 0.1420\n",
      "resnet18.layer4.0.conv2.weight: 30.8621\n",
      "resnet18.layer4.0.bn2.weight: 20.7293\n",
      "resnet18.layer4.0.bn2.bias: 1.5412\n",
      "resnet18.layer4.0.downsample.0.weight: 21.9693\n",
      "resnet18.layer4.0.downsample.1.weight: 20.7370\n",
      "resnet18.layer4.0.downsample.1.bias: 1.5412\n",
      "resnet18.layer4.1.conv1.weight: 30.8400\n",
      "resnet18.layer4.1.bn1.weight: 21.5333\n",
      "resnet18.layer4.1.bn1.bias: 0.1348\n",
      "resnet18.layer4.1.conv2.weight: 30.7922\n",
      "resnet18.layer4.1.bn2.weight: 19.0352\n",
      "resnet18.layer4.1.bn2.bias: 3.3503\n",
      "resnet18.fc.weight: 3.8980\n",
      "resnet18.fc.bias: 0.1872\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name}: {torch.norm(param.data):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet18.conv1.weight: 9.8421\n",
      "resnet18.bn1.weight: 8.0017\n",
      "resnet18.bn1.bias: 0.6670\n",
      "resnet18.layer1.0.conv1.weight: 11.8414\n",
      "resnet18.layer1.0.bn1.weight: 7.6199\n",
      "resnet18.layer1.0.bn1.bias: 0.4097\n",
      "resnet18.layer1.0.conv2.weight: 11.7206\n",
      "resnet18.layer1.0.bn2.weight: 7.4228\n",
      "resnet18.layer1.0.bn2.bias: 0.2968\n",
      "resnet18.layer1.1.conv1.weight: 11.4897\n",
      "resnet18.layer1.1.bn1.weight: 7.6158\n",
      "resnet18.layer1.1.bn1.bias: 0.2748\n",
      "resnet18.layer1.1.conv2.weight: 11.3751\n",
      "resnet18.layer1.1.bn2.weight: 7.4234\n",
      "resnet18.layer1.1.bn2.bias: 0.2078\n",
      "resnet18.layer2.0.conv1.weight: 11.8333\n",
      "resnet18.layer2.0.bn1.weight: 10.7678\n",
      "resnet18.layer2.0.bn1.bias: 0.2659\n",
      "resnet18.layer2.0.conv2.weight: 16.0075\n",
      "resnet18.layer2.0.bn2.weight: 10.6751\n",
      "resnet18.layer2.0.bn2.bias: 0.2699\n",
      "resnet18.layer2.0.downsample.0.weight: 10.9528\n",
      "resnet18.layer2.0.downsample.1.weight: 10.9444\n",
      "resnet18.layer2.0.downsample.1.bias: 0.2699\n",
      "resnet18.layer2.1.conv1.weight: 15.9238\n",
      "resnet18.layer2.1.bn1.weight: 10.7672\n",
      "resnet18.layer2.1.bn1.bias: 0.2297\n",
      "resnet18.layer2.1.conv2.weight: 15.7908\n",
      "resnet18.layer2.1.bn2.weight: 10.6850\n",
      "resnet18.layer2.1.bn2.bias: 0.1724\n",
      "resnet18.layer3.0.conv1.weight: 16.2253\n",
      "resnet18.layer3.0.bn1.weight: 15.2269\n",
      "resnet18.layer3.0.bn1.bias: 0.2152\n",
      "resnet18.layer3.0.conv2.weight: 22.1628\n",
      "resnet18.layer3.0.bn2.weight: 15.2321\n",
      "resnet18.layer3.0.bn2.bias: 0.1913\n",
      "resnet18.layer3.0.downsample.0.weight: 15.4160\n",
      "resnet18.layer3.0.downsample.1.weight: 15.2531\n",
      "resnet18.layer3.0.downsample.1.bias: 0.1913\n",
      "resnet18.layer3.1.conv1.weight: 22.0006\n",
      "resnet18.layer3.1.bn1.weight: 15.2266\n",
      "resnet18.layer3.1.bn1.bias: 0.1429\n",
      "resnet18.layer3.1.conv2.weight: 21.9160\n",
      "resnet18.layer3.1.bn2.weight: 15.1973\n",
      "resnet18.layer3.1.bn2.bias: 0.1186\n",
      "resnet18.layer4.0.conv1.weight: 22.1899\n",
      "resnet18.layer4.0.bn1.weight: 21.5333\n",
      "resnet18.layer4.0.bn1.bias: 0.1420\n",
      "resnet18.layer4.0.conv2.weight: 30.8621\n",
      "resnet18.layer4.0.bn2.weight: 20.7293\n",
      "resnet18.layer4.0.bn2.bias: 1.5412\n",
      "resnet18.layer4.0.downsample.0.weight: 21.9693\n",
      "resnet18.layer4.0.downsample.1.weight: 20.7370\n",
      "resnet18.layer4.0.downsample.1.bias: 1.5412\n",
      "resnet18.layer4.1.conv1.weight: 30.8400\n",
      "resnet18.layer4.1.bn1.weight: 21.5333\n",
      "resnet18.layer4.1.bn1.bias: 0.1348\n",
      "resnet18.layer4.1.conv2.weight: 30.7922\n",
      "resnet18.layer4.1.bn2.weight: 19.0352\n",
      "resnet18.layer4.1.bn2.bias: 3.3503\n",
      "resnet18.fc.weight: 3.8980\n",
      "resnet18.fc.bias: 0.1872\n",
      "tensor(647.4965)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name}: {torch.norm(param.data):.4f}\")\n",
    "        count += torch.norm(param.data)\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet18.conv1.weight: 9.8440\n",
      "resnet18.bn1.weight: 8.0611\n",
      "resnet18.bn1.bias: 0.7251\n",
      "resnet18.layer1.0.conv1.weight: 11.5586\n",
      "resnet18.layer1.0.bn1.weight: 7.2694\n",
      "resnet18.layer1.0.bn1.bias: 0.4568\n",
      "resnet18.layer1.0.conv2.weight: 11.6408\n",
      "resnet18.layer1.0.bn2.weight: 6.8925\n",
      "resnet18.layer1.0.bn2.bias: 0.4752\n",
      "resnet18.layer1.1.conv1.weight: 11.4017\n",
      "resnet18.layer1.1.bn1.weight: 7.2609\n",
      "resnet18.layer1.1.bn1.bias: 0.3661\n",
      "resnet18.layer1.1.conv2.weight: 11.3618\n",
      "resnet18.layer1.1.bn2.weight: 6.8239\n",
      "resnet18.layer1.1.bn2.bias: 0.3658\n",
      "resnet18.layer2.0.conv1.weight: 11.7671\n",
      "resnet18.layer2.0.bn1.weight: 10.2493\n",
      "resnet18.layer2.0.bn1.bias: 0.3135\n",
      "resnet18.layer2.0.conv2.weight: 15.8296\n",
      "resnet18.layer2.0.bn2.weight: 10.0152\n",
      "resnet18.layer2.0.bn2.bias: 0.3624\n",
      "resnet18.layer2.0.downsample.0.weight: 10.7954\n",
      "resnet18.layer2.0.downsample.1.weight: 10.7080\n",
      "resnet18.layer2.0.downsample.1.bias: 0.3624\n",
      "resnet18.layer2.1.conv1.weight: 15.8265\n",
      "resnet18.layer2.1.bn1.weight: 10.2464\n",
      "resnet18.layer2.1.bn1.bias: 0.3096\n",
      "resnet18.layer2.1.conv2.weight: 15.6129\n",
      "resnet18.layer2.1.bn2.weight: 10.0087\n",
      "resnet18.layer2.1.bn2.bias: 0.3236\n",
      "resnet18.layer3.0.conv1.weight: 16.1273\n",
      "resnet18.layer3.0.bn1.weight: 14.4839\n",
      "resnet18.layer3.0.bn1.bias: 0.3284\n",
      "resnet18.layer3.0.conv2.weight: 21.4729\n",
      "resnet18.layer3.0.bn2.weight: 14.4766\n",
      "resnet18.layer3.0.bn2.bias: 0.2580\n",
      "resnet18.layer3.0.downsample.0.weight: 14.8658\n",
      "resnet18.layer3.0.downsample.1.weight: 14.5994\n",
      "resnet18.layer3.0.downsample.1.bias: 0.2580\n",
      "resnet18.layer3.1.conv1.weight: 21.1067\n",
      "resnet18.layer3.1.bn1.weight: 14.4833\n",
      "resnet18.layer3.1.bn1.bias: 0.2059\n",
      "resnet18.layer3.1.conv2.weight: 21.0042\n",
      "resnet18.layer3.1.bn2.weight: 14.3819\n",
      "resnet18.layer3.1.bn2.bias: 0.1708\n",
      "resnet18.layer4.0.conv1.weight: 21.2716\n",
      "resnet18.layer4.0.bn1.weight: 20.4824\n",
      "resnet18.layer4.0.bn1.bias: 0.1979\n",
      "resnet18.layer4.0.conv2.weight: 29.4504\n",
      "resnet18.layer4.0.bn2.weight: 19.7050\n",
      "resnet18.layer4.0.bn2.bias: 1.8234\n",
      "resnet18.layer4.0.downsample.0.weight: 21.1788\n",
      "resnet18.layer4.0.downsample.1.weight: 19.6371\n",
      "resnet18.layer4.0.downsample.1.bias: 1.8234\n",
      "resnet18.layer4.1.conv1.weight: 29.3977\n",
      "resnet18.layer4.1.bn1.weight: 20.4826\n",
      "resnet18.layer4.1.bn1.bias: 0.1752\n",
      "resnet18.layer4.1.conv2.weight: 29.4164\n",
      "resnet18.layer4.1.bn2.weight: 16.7147\n",
      "resnet18.layer4.1.bn2.bias: 4.8910\n",
      "resnet18.fc.weight: 4.7921\n",
      "resnet18.fc.bias: 0.3296\n",
      "tensor(627.2267)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name}: {torch.norm(param.data):.4f}\")\n",
    "        count += torch.norm(param.data)\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipynb",
   "language": "python",
   "name": "demo_graph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
